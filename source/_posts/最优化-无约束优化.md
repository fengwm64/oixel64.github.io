---
title: '[最优化]无约束优化'
date: 2024-05-03 15:47:04
tags:
- 最优化
- 无约束优化
- 牛顿法
- 最速下降法
---

# 1.牛顿法

## 1.1 原理

牛顿法的原理是基于使用一个**二次函数**去近似目标函数，然后精确地求出这个二次函数的极小点作为新的迭代点，从而逐步优化目标函数的过程

1. **二次函数的选取**：牛顿法通过在当前点处使用目标函数的二阶泰勒展开式来构建一个二次函数作为近似。在点 $x_k$ 处，目标函数 $f(x)$ 的二阶泰勒展开式为：

   $$ f(x+s) \approx f(x_k) + \nabla f(x_k)^{T}s + \frac{1}{2} s^{T} \nabla^2 f(x_k) s =: m_k(s) $$

   其中，$\nabla f(x_k)$ 是目标函数在 $x_k$ 处的梯度，$\nabla^2 f(x_k)$ 是目标函数在 $x_k$ 处的Hessian矩阵。

2. **迭代方向的选取**：牛顿法的关键在于求解二次函数 $m_k(s)$ 的极小点，作为下一步迭代的方向。通过令二次函数的一阶导数为零，即 $\nabla m_k(s) = 0$，解出极小点所对应的 $s$ 值，即为牛顿方向。

3. **迭代更新**：一旦求得牛顿方向 $s$，将其应用于当前点 $x_k$，即 $x_{k+1} = x_k + s$，得到下一次迭代的点 $x_{k+1}$。

4. **收敛性**：如果初始点选择得当，且目标函数在局部区域内表现得足够光滑，那么牛顿法往往能够快速收敛到局部极小值点。这是因为牛顿法具有至少二阶收敛速度，即每次迭代都会更快地逼近极小值点。

总结，牛顿法利用二次函数近似目标函数，并通过精确求解二次函数的极小点来指导迭代方向，以加速目标函数的优化过程。



## 1.2 算法步骤：

1. **初始化**：
  
   - 选择初始点 $x_0$。
   
   - 设置精度参数 $\epsilon$，用于控制算法收敛的条件。
  
   - 初始化迭代次数 $k = 0$。


2. **迭代过程**：
   
   - **计算梯度和Hessian矩阵**：
     - 计算目标函数在当前点 $x_k$ 处的梯度 $g_k = \nabla f(x_k)$。
     - 计算目标函数在当前点 $x_k$ 处的Hessian矩阵 $H_k = \nabla^2 f(x_k)$。
  
   - **解牛顿方程**：
     - 计算牛顿方向 $d_k^N = - (H_k)^{-1} g_k$。
   
   - **更新参数**：
     - 更新迭代点：$x_{k+1} = x_k + d_k^N$。


3. **判断停止条件**：
   - 如果 $\| g_k \| \leq \epsilon$，则算法收敛，停止迭代。
   
   - 否则，将 $k$ 更新为 $k + 1$，并回到步骤2。
