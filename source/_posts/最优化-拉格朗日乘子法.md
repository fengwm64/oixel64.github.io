---
title: '[最优化]拉格朗日乘子法'
date: 2024-04-23 22:13:31
categories: 最优化
tags: 
- 最优化
- 拉格朗日
- KKT条件
---

# 0.无约束优化问题

**问题形式：**
$\mathop {\min}\limits_{\mathbf{x}\in\mathbb{R}^2}f(\mathbf{x})$

对一个无约束问题，$x^*$是一个**局部极小值**的必要条件是：

1. **一阶必要条件**，$f$在$x^*$处取得0梯度： $\nabla_\mathbf{x}f(\mathbf{x}^*)=\mathbf{0}$
   
2. **二阶必要条件**，在该点处黑塞矩阵(Hessian)半正定：

    $\mathbf{v}^t\left(\nabla^2f(\mathbf{x}^*)\right)\mathbf{v}\geq\mathbf{0},\mathrm{~}\forall\mathbf{v}\in\mathbb{R}^n$，$\nabla^2f(\mathbf{x})=\begin{pmatrix}\frac{\partial^2f(\mathbf{x})}{\partial x_1^2}&\cdots&\frac{\partial^2f(\mathbf{x})}{\partial x_1\partial x_n}\\\vdots&\ddots&\vdots\\\frac{\partial^2f(\mathbf{x})}{\partial x_n\partial x_1}&\cdots&\frac{\partial^2f(\mathbf{x})}{\partial x_n^2}\end{pmatrix}$

    $\mathbf{v}$ 是任意的非零向量。

    $\mathbf{v}^t\left(\nabla^2f(\mathbf{x})\right)\mathbf{v}$ 是向量 $\mathbf{v}$ 关于黑塞矩阵 $\nabla^2f(\mathbf{x})$ 的二次型。

    不等式 $\mathbf{v}^t\left(\nabla^2f(\mathbf{x}^*)\right)\mathbf{v}\geq\mathbf{0}$ 表示二次型是半正定的，也就是说，对于任何非零向量 $\mathbf{v}$，二次型的值都大于等于零。

--------------------------

>Hessian矩阵的正定性在判断优化算法可行性时非常有用，简单地说，黑塞矩阵正定，则
>
>1. 函数的二阶偏导数恒 > 0
>2. 函数的变化率（斜率）即一阶导数始终处于递增状态
>3. 函数为凸

# 1.等式约束问题

**问题形式：**
$\mathop {\min}\limits_{\mathbf{x}\in\mathbb{R}^2}f(\mathbf{x})\text{ subject to }h(\mathbf{x})=0$

**举例：**$f(\mathbf{x})=x_1+x_2\textbf{ and }h(\mathbf{x})=x_1^2+x_2^2-2$

## 1.1 感性角度

上述问题可视化如下：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242150096.png)

图中左上角的橙色点处，往哪里走达到约束下的最小值？

假设是无约束优化问题，我们知道直接往**目标函数负梯度**方向走，就可以到达最小

但是现在有一个等式的约束，只能在约束（实际上就是图中的橙色圆）上移动，**在圆上移动只能沿着切线方向移动**，只要保证**每次移动都满足移动方向和目标函数负梯度方向夹角小于90°**，就是在向极小值移动！

当移动到图中左下的蓝色点位置时，此刻无论向圆的哪个切线方向移动，**夹角都为90°**，不满足移动方向和目标函数负梯度方向夹角小于90°了，此时就认为达到了极小值。观察到此时目标函数的负梯度方向与约束函数的梯度方向满足**线性关系（在一条线上）**，即：$\nabla_\mathbf{x}f(\mathbf{x}^*)=\mu\nabla_\mathbf{x}h(\mathbf{x}^*)$


## 1.2 拉格朗日乘子法

我们从一种感性的认知上找到了等式约束下的极小值，现在回到拉格朗日乘子法：

定义拉格朗日函数：
$\mathcal{L}(\mathbf{x},\mu)=f(\mathbf{x})+\mu h(\mathbf{x})$

$x^*$是极小值的**充要条件**是**存在唯一**的$\mu^{*}$满足
$$
\begin{align}
&\nabla_{\mathbf{x}}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=\mathbf{0} \tag{1} \\
&\nabla_{\mu}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=0 \tag{2} \\
&\mathbf{y}^{t}(\nabla_{\mathbf{x}\mathbf{x}}^{2}\mathcal{L}(\mathbf{x}^{*},\mu^{*}))\mathbf{y}\geq0 \quad\forall\mathbf{y} \text{ s.t. } \nabla_{\mathbf{x}}h(\mathbf{x}^{*})^{t}\mathbf{y}=0 \tag{3}
\end{align}
$$


**第一条：**$\nabla_{\mathbf{x}}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=\mathbf{0}$

> $\nabla_{\mathbf{x}}\mathcal{L}$是拉格朗日函数对$x$求**梯度**，
>
> 求梯度的结果是 $\nabla_{\mathbf{x}}\mathcal{L}=\nabla_\mathbf{x}f(\mathbf{x})+\mu\nabla_\mathbf{x}h(\mathbf{x})$
>
> 则原式为 $\nabla_{\mathbf{x}}\mathcal{L}=\nabla_\mathbf{x}f(\mathbf{x})+\mu\nabla_\mathbf{x}h(\mathbf{x}) = 0$
>
> 稍微移动变形 $\nabla_\mathbf{x}f(\mathbf{x})=\mu\nabla_\mathbf{x}h(\mathbf{x})$ ；注意$\mu$是未知数正负其实无所谓
>
> 此时，再看感性认知部分最后的目标函数的负梯度方向与约束函数的梯度方向满足**线性关系（在一条线上）** 是一致的，这里保证所求一定是一个**极值**


**第二条：**$\nabla_{\mu}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=0$

> $\nabla_{\mathbf{\mu}}\mathcal{L}$是拉格朗日函数对$\mu$求**梯度**，
> 
> 求梯度结果 $\nabla_{\mathbf{\mu}}\mathcal{L}=h(\mathbf{x})$
>
> 则原式为 $h(\mathbf{x})=0$
>
> $h(\mathbf{x})=0$就是**约束条件**，这里保证了所求一定是满足约束条件的

**第三条：** 保证满足半正定，确定存在一个极小值

--------------------------

**注意：如果是一个凸优化问题，满足(1)&(2)就可以找到极小值点（且为全局最小值点，充要条件）；若非凸优化问题，仅满足(1)&(2)是必要条件，需要加上(3)才是充要条件**

# 2.不等式约束问题

**问题形式：**
$\mathop {\min}\limits_{\mathbf{x}\in\mathbb{R}^2}f(\mathbf{x})\text{ subject to }h(\mathbf{x})\leq0$

- 拉格朗日函数构造和上面一样

- 注意**极值点只能出现在约束边界上**

--------------------------------

**松约束**，约束改变没起作用，加了和没加一样：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242244909.png)


**紧约束**，约束起作用：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242246169.png)

对于上面两种约束求解最小值的条件总结如下：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242256428.png)

将两种形式整合在一起，就形成了**KKT条件**（单条不等式约束时）：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242259660.png)

**多条不等式约束KKT条件**：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242301278.png)

# 3.混合约束问题

**多条混合等式、不等式约束KKT条件**：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242303087.png)


# 4.总结

1. 无约束问题：直接令梯度等于0求解

2. 等式约束问题：构造拉格朗日函数，对各个分量求偏导，令各个分量偏导为0，即可解出极小值

3. 不等式约束问题：构造拉格朗日函数，代入KKT条件求解

4. KKT条件求的是局部最值/极值。只要满足最后一条**二阶条件**无论凸问题、非凸问题，KKT条件都可以求得极值。


# 5.参考资料

通俗易懂讲算法-最优化之拉格朗日乘子与KKT条件:
https://www.bilibili.com/video/BV14q4y187wg

“拉格朗日对偶问题”如何直观理解？“KKT条件” “Slater条件” “凸优化”打包理解:
https://www.bilibili.com/video/BV1HP4y1Y79e

瑞典皇家理工学院（KTH）“统计学习基础”课程的KKT课件：
http://www.csc.kth.se/utbildning/kth/kurser/DD3364/Lectures/KKT.pdf

拉格朗日乘子法和KKT条件：
https://www.cnblogs.com/liaohuiqiang/p/7805954.html