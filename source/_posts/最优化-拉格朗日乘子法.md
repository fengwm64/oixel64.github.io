---
title: '[最优化]拉格朗日乘子法'
date: 2024-04-23 22:13:31
categories: 最优化
tags: 
- 最优化
- 拉格朗日
---

# 0.无约束优化问题

**问题形式：**
$\mathop {\min}\limits_{\mathbf{x}\in\mathbb{R}^2}f(\mathbf{x})$

对一个无约束问题，$x^*$是一个**局部极小值**的必要条件是：

1. **一阶必要条件**，$f$在$x^*$处取得0梯度： $\nabla_\mathbf{x}f(\mathbf{x}^*)=\mathbf{0}$
   
2. **二阶必要条件**，在该点处黑塞矩阵(Hessian)半正定：

    $\mathbf{v}^t\left(\nabla^2f(\mathbf{x}^*)\right)\mathbf{v}\geq\mathbf{0},\mathrm{~}\forall\mathbf{v}\in\mathbb{R}^n$，$\nabla^2f(\mathbf{x})=\begin{pmatrix}\frac{\partial^2f(\mathbf{x})}{\partial x_1^2}&\cdots&\frac{\partial^2f(\mathbf{x})}{\partial x_1\partial x_n}\\\vdots&\ddots&\vdots\\\frac{\partial^2f(\mathbf{x})}{\partial x_n\partial x_1}&\cdots&\frac{\partial^2f(\mathbf{x})}{\partial x_n^2}\end{pmatrix}$

    $\mathbf{v}$ 是任意的非零向量。

    $\mathbf{v}^t\left(\nabla^2f(\mathbf{x})\right)\mathbf{v}$ 是向量 $\mathbf{v}$ 关于黑塞矩阵 $\nabla^2f(\mathbf{x})$ 的二次型。

    不等式 $\mathbf{v}^t\left(\nabla^2f(\mathbf{x}^*)\right)\mathbf{v}\geq\mathbf{0}$ 表示二次型是半正定的，也就是说，对于任何非零向量 $\mathbf{v}$，二次型的值都大于等于零。

--------------------------

>Hessian矩阵的正定性在判断优化算法可行性时非常有用，简单地说，黑塞矩阵正定，则
>
>1. 函数的二阶偏导数恒 > 0
>
>2. 函数的变化率（斜率）即一阶导数始终处于递增状态
>
>3. 函数为凸

# 1.等式约束问题
**问题形式：**
$\mathop {\min}\limits_{\mathbf{x}\in\mathbb{R}^2}f(\mathbf{x})\text{ subject to }h(\mathbf{x})=0$

**举例：**$f(\mathbf{x})=x_1+x_2\textbf{ and }h(\mathbf{x})=x_1^2+x_2^2-2$

## 1.1 感性角度

上述问题可视化如下：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242150096.png)

图中左上角的橙色点处，往哪里走达到约束下的最小值？

假设是无约束优化问题，我们知道直接往**目标函数负梯度**方向走，就可以到达最小

但是现在有一个等式的约束，只能在约束（实际上就是图中的橙色圆）上移动，**在圆上移动只能沿着切线方向移动**，只要保证**每次移动都满足移动方向和目标函数负梯度方向夹角小于90°**，就是在向极小值移动！

当移动到图中左下的蓝色点位置时，此刻无论向圆的哪个切线方向移动，**夹角都为90°**，不满足移动方向和目标函数负梯度方向夹角小于90°了，此时就认为达到了极小值。观察到此时目标函数的负梯度方向与约束函数的梯度方向满足**线性关系（在一条线上）**，即：$\nabla_\mathbf{x}f(\mathbf{x}^*)=\mu\nabla_\mathbf{x}h(\mathbf{x}^*)$


## 1.2 拉格朗日乘子法

我们从一种感性的认知上找到了等式约束下的极小值，现在回到拉格朗日乘子法：

定义拉格朗日函数：
$\mathcal{L}(\mathbf{x},\mu)=f(\mathbf{x})+\mu h(\mathbf{x})$

$x^*$是极小值的**充要条件**是**存在唯一**的$\mu^{*}$满足
$$
\begin{align}
&\nabla_{\mathbf{x}}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=\mathbf{0} \tag{1} \\
&\nabla_{\mu}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=0 \tag{2} \\
&\mathbf{y}^{t}(\nabla_{\mathbf{x}\mathbf{x}}^{2}\mathcal{L}(\mathbf{x}^{*},\mu^{*}))\mathbf{y}\geq0 \quad\forall\mathbf{y} \text{ s.t. } \nabla_{\mathbf{x}}h(\mathbf{x}^{*})^{t}\mathbf{y}=0 \tag{3}
\end{align}
$$


**第一条：**$\nabla_{\mathbf{x}}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=\mathbf{0}$

> $\nabla_{\mathbf{x}}\mathcal{L}$是拉格朗日函数对$x$求**梯度**，
>

> 求梯度的结果是 $\nabla_{\mathbf{x}}\mathcal{L}=\nabla_\mathbf{x}f(\mathbf{x})+\mu\nabla_\mathbf{x}h(\mathbf{x})$
>
> 则原式为 $\nabla_{\mathbf{x}}\mathcal{L}=\nabla_\mathbf{x}f(\mathbf{x})+\mu\nabla_\mathbf{x}h(\mathbf{x}) = 0$
>
> 稍微移动变形 $\nabla_\mathbf{x}f(\mathbf{x})=\mu\nabla_\mathbf{x}h(\mathbf{x})$ ；注意$\mu$是未知数正负其实无所谓
>
> 此时，再看感性认知部分最后的目标函数的负梯度方向与约束函数的梯度方向满足**线性关系（在一条线上）** 是一致的，这里保证所求一定是一个**极值**


**第二条：**$\nabla_{\mu}\mathcal{L}(\mathbf{x}^{*},\mu^{*})=0$

> $\nabla_{\mathbf{\mu}}\mathcal{L}$是拉格朗日函数对$\mu$求**梯度**，
> 
> 求梯度结果 $\nabla_{\mathbf{\mu}}\mathcal{L}=h(\mathbf{x})$
>
> 则原式为 $h(\mathbf{x})=0$
>
> $h(\mathbf{x})=0$就是**约束条件**，这里保证了所求一定是满足约束条件的

**第三条：** 保证满足半正定，确定存在一个极小值

# 2.不等式约束问题

## 2.1 约束分类

### 2.1.1 松约束

约束改变没起作用，加了和没加一样：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242244909.png)


### 2.1.2 紧约束

约束起作用：

![](https://cdn.jsdelivr.net/gh/oixel64/imgs/imgs/202404242246169.png)




# 3.混合约束问题





# 4.参考资料

https://www.bilibili.com/video/BV14q4y187wg

